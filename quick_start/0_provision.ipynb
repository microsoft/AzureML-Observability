{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (pyarrow 7.0.0 (c:\\users\\janguy\\anaconda3\\envs\\dlresearch\\lib\\site-packages), Requirement.parse('pyarrow<4.0.0,>=0.17.0'), {'azureml-dataset-runtime'}).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (azureml-core 1.39.0 (c:\\users\\janguy\\anaconda3\\envs\\dlresearch\\lib\\site-packages), Requirement.parse('azureml-core~=1.38.0')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (azureml-core 1.39.0 (c:\\users\\janguy\\anaconda3\\envs\\dlresearch\\lib\\site-packages), Requirement.parse('azureml-core~=1.38.0')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (azureml-core 1.39.0 (c:\\users\\janguy\\anaconda3\\envs\\dlresearch\\lib\\site-packages), Requirement.parse('azureml-core~=1.38.0')).\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "from aml_obs.management import provision\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from aml_obs.collector import Online_Collector\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provision Resources\n",
    "\n",
    "#### Create ADX Cluster, Service Principal, and store value's in Azure Machine Learning's Key Vault for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provision(ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "\n",
    "Once the resources are created, data can now be ingested to Azure Data Explorer. To use the dashboards, the data must have a timestamp column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get raw data\n",
    "\n",
    "dataset = pd.read_csv(\"https://azuremlexamples.blob.core.windows.net/datasets/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nserafino\\Anaconda3\\envs\\mlopsenv\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2199: FutureWarning: The parsing of 'now' in pd.to_datetime without `utc=True` is deprecated. In a future version, this will match Timestamp('now') and Timestamp.now()\n",
      "  result, tz_parsed = tslib.array_to_datetime(\n"
     ]
    }
   ],
   "source": [
    "# Add timestamp column\n",
    "\n",
    "dataset[\"datetime\"] =  [pd.to_datetime('now') - timedelta(days=x) for x in range(len(dataset))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "\n",
    "dataset.to_parquet(\"data/iris.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Ingestion\n",
    "\n",
    "Entire dataframe will be loaded into ADX at once as a table named ```irisdata```. The is also a stream ingestion available to ingest data asynchronously with an internal buffering mechanism. This method can be utilized to lower impact to main scoring thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "table_name = \"irisdata\" #new dataset\n",
    "\n",
    "sample_pd_data = pd.read_parquet(\"data/iris.parquet\").head(10)\n",
    "\n",
    "online_collector = Online_Collector(table_name,ws=ws)\n",
    "online_collector.batch_collect(sample_pd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://adx02.westus2.kusto.windows.net'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get cluster uri to use in browser\n",
    "\n",
    "online_collector.cluster_uri"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8858a4df92b06e9052bc306608e3218c33233584bc6448961c72d65ba55843de"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('dlresearch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
