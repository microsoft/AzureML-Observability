{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (pyarrow 7.0.0 (c:\\users\\janguy\\anaconda3\\envs\\dlresearch\\lib\\site-packages), Requirement.parse('pyarrow<4.0.0,>=0.17.0'), {'azureml-dataset-runtime'}).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (azureml-core 1.39.0 (c:\\users\\janguy\\anaconda3\\envs\\dlresearch\\lib\\site-packages), Requirement.parse('azureml-core~=1.38.0')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (azureml-core 1.39.0 (c:\\users\\janguy\\anaconda3\\envs\\dlresearch\\lib\\site-packages), Requirement.parse('azureml-core~=1.38.0')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (azureml-core 1.39.0 (c:\\users\\janguy\\anaconda3\\envs\\dlresearch\\lib\\site-packages), Requirement.parse('azureml-core~=1.38.0')).\n"
     ]
    }
   ],
   "source": [
    "from aml_obs.drift import Drift_Analysis\n",
    "from aml_obs.collector import Online_Collector\n",
    "from aml_obs.query import RT_Visualization\n",
    "from azureml.core import Workspace\n",
    "import pandas as pd\n",
    "from azureml.core.model import Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "ws = Workspace.from_config()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real time metrics logging and visualization\n",
    "#### You need to run this using your local computer or if you run with Azure ML Compute Instance, please do so from VSCode as Dash visualization requires access to localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest streaming data  asynchronously with internal buffering mechanism to lower impact to main scoring thread\n",
    "streaming_table_name=\"streaming_test\"\n",
    "streaming_collector = Online_Collector(streaming_table_name,ws=ws)\n",
    "\n",
    "import random\n",
    "streaming_collector.start_logging_daemon(buffer_time=2, batch_size=10)\n",
    "\n",
    "for run_id in [\"r000001\", \"r000002\", \"r000003\", \"r000004\", \"r000005\"]:\n",
    "    for i in range(1000):\n",
    "        for lr in [\"0.001\", \"0.002\"]:\n",
    "            df = pd.DataFrame({ \"timestamp\":pd.to_datetime('today'), \"lr\":[lr],\"metric1\":[random.uniform(3,50)] })\n",
    "            streaming_collector.stream_collect_df_queue(df)\n",
    "# streaming_collector.stop_logging_daemon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from monitoring.query import RT_Visualization\n",
    "streaming_table_name=\"streaming_test\"\n",
    "rt_viz =RT_Visualization(streaming_table_name,ws)\n",
    "rt_viz.scatter(max_records=200, ago='12h',groupby='lr', y_metric='metric1',x_metric='timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deploy_model utility install AML CLI v2, create managed online endpoint, deploy the model. These steps are optional incase you want to supply your own names and objects. Check the function to see all paramters. The below just create everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Install ML CLI v2\n",
      "Creating managed online endpoint  \n",
      "creating online endpoint with name  iris-ep6667\n",
      "az ml online-endpoint create -f deployment/endpoint.yml --name iris-ep6667\n",
      "Deploy ML model \n",
      "deployment is done\n"
     ]
    }
   ],
   "source": [
    "from deployment.deploy_util import deploy_model,score_test\n",
    "\n",
    "scoring_uri, scoring_key = deploy_model(ws=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the model deployed with the collector object inside, you can just call it to simulate data creation. Data is collected to ADX table nIRIS_MODEL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[\"setosa\", \"versicolor\", \"setosa\", \"virginica\", \"setosa\", \"versicolor\", \"virginica\", \"virginica\", \"versicolor\", \"versicolor\"]'\n",
      "b'[\"virginica\", \"setosa\", \"setosa\", \"setosa\", \"virginica\", \"versicolor\", \"versicolor\", \"setosa\", \"setosa\", \"versicolor\"]'\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for _ in range(1000):\n",
    "    time.sleep(3)\n",
    "    score_test(scoring_uri, scoring_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that data is collected. Go to ADX Dashboard and import the quick_start/ADX_dashboards/databoard_Model_Monitoring.json to create a monitoring dashboard for your model.\n",
    "\n",
    "Review https://docs.microsoft.com/en-us/azure/data-explorer/azure-data-explorer-dashboards#to-create-new-dashboard-from-a-file for instruction on how to import the dashboard.\n",
    "\n",
    "You may need to correct a few default paramters such as connection to make dashboard work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8858a4df92b06e9052bc306608e3218c33233584bc6448961c72d65ba55843de"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('dlresearch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
